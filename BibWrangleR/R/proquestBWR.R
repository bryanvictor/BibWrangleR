#' Converts bibliographic text files extracted from ProQuest into analyzable data frame
#' @param csv - logical vector indicating whether the final data frame generated by the function should be saved to the working directory as a .csv file
#' @param path - path for the folder containing text files to be wrangled
#' @examples proQuestBWR.f(csv=TRUE, path="C:/Users/JohnDoe/Desktop/ProQuestTextFiles")
#' @note proQuestBWR.f will wrangle all text files present in the path folder.  
#' @export


proQuestBWR.f <- function(csv = FALSE, path){

  #_______________________________________________________________________________
  #                       0. Install Missing Packages
  #-------------------------------------------------------------------------------
  #
  #All files to be wrangled should be saved in a single folder and have a *.txt
  #extension.  The files must be processed from EbscoHost in the generic
  #bibliographic format -- no other file structure will work.
  #
  #_______________________________________________________________________________

  path <- "/Users/beperron/Git/SocialWorkResearch/Data/proQuest"
  pkgs <- c("dplyr", "stringi", "stringr")
  pkgs_miss <- pkgs[which(!pkgs %in% installed.packages()[, 1])]
  if (length(pkgs_miss) > 0) {
    message("\n ...Installing missing packages!\n")
    install.packages(pkgs_miss)
  }

  if (length(pkgs_miss) == 0) {
    message("\n ...Packages were already installed!\n")
  }

    #___________________________________________________________________________
    #                           1. READ ProQuest txt files
    #---------------------------------------------------------------------------
    #
    # Check last line of txt file.  Clean up might be necessary
    #___________________________________________________________________________

    library(dplyr)
    temp <- list.files(path, pattern = ".txt", full.names=TRUE)
    record <- unlist(lapply(temp, readLines))

    indx <- which(grepl('\\_{10}', record))
    record[indx+2] <- paste0('Article: ', record[indx+2])


    # extract attributes as a separate variable
    attributes <- stringr::str_extract(record, "(.*?):")
    full.df <- data.frame(cbind(attributes, record))

    full.df <- tbl_df(full.df) #Convert to dplyr table for easier reading
    full.df <- filter(full.df, record != "") #Eliminate empy rows
    full.df <- filter(full.df, record = !(is.na(attributes))) #Eliminate missing
    full.df$attributes <- gsub(" ", "", full.df$attributes)
    full.df$attributes <- gsub(":", "", full.df$attributes)

    full.df$articleID <- cumsum(full.df$attributes == "Article")
    full.df$record <- gsub("^[^:]+:", "", full.df$record)

    #_______________________________________________________________________________
    #            AUTHOR FIELD FIX - AUTHORS IN SINGLE FIELD
    #-------------------------------------------------------------------------------
    #
    # Social Work abstracts lists authors in a single cell, separated by a semi-
    # colon, and then includes digits and email addresses in some occassions.
    # The following text locates each author in the cell and places it into a new
    # row to be consistent with PsychInfo and SSA.
    #_______________________________________________________________________________


        #Create a new temporary data frame
        DF.temp <- filter(full.df, attributes == "Author")

        #Identify records with semi-colons in author names
        semi.colons <- grepl("(;)", DF.temp$record)

        #Select out those records with semi-colons in author names from temporary
        #data frame
        DF.temp <- DF.temp[semi.colons, ]

        #Add a semi colon to the end of every string
        DF.temp$record <- paste(DF.temp$record, ";", sep="")
        semi.colon.split <- strsplit(DF.temp$record, ";")

        split.df <- data.frame(
            attributes = rep(DF.temp$attributes, lapply(semi.colon.split, length)),
            record = unlist(semi.colon.split),
            articleID = rep(DF.temp$articleID, lapply(semi.colon.split, length)))

        #Trim whitespace on both sides
        split.df$record <- stringr::str_trim(split.df$record, side = "both")

        #Eliminate author affiliation from author record
        split.df$record <- gsub("1\\s.+", "", split.df$record)

        #Eliminate remaining number from author record
        split.df$record <- gsub("1", "", split.df$record)

        # Create a vector of all articleID's that were fixed
        fixed.ID <- unique(split.df$articleID)

        #Filter out all processed records from the fixed list
        DF.authors <- filter(full.df, attributes == "Author")
        DF.authors.good <- DF.authors[!(DF.authors$articleID %in% fixed.ID),]
        DF.authors.fixed <- split.df
        DF.no.authors <- filter(full.df, attributes != "Author")

        #Strip author biographies
        DF.authors.good$record <- gsub("11\\s.+", "", DF.authors.good$record)

        #Bind the reduced DF with the fixed df
        DF <- rbind(DF.no.authors, DF.authors.good, DF.authors.fixed)
        DF <- arrange(DF, articleID)

  #_______________________________________________________________________________
  #            KEYWORD FIELD FIX - KEYWORDS IN SINGLE FIELD
  #-------------------------------------------------------------------------------
  #
  # Social Work abstracts lists authors in a single cell, separated by a semi-
  # colon, and then includes digits and email addresses in some occassions.
  # The following text locates each author in the cell and places it into a new
  # row to be consistent with PsychInfo and SSA.
  #_______________________________________________________________________________


  #Create a new temporary data frame
  full.df$attributes <- ifelse(full.df$attributes == "Subject",
        "keyWord", full.df$attributes)

  DF.temp <- filter(full.df, attributes == "keyWord")

  #Add a comma to the end of every string
  DF.temp$record <- paste(DF.temp$record, ";", sep="")
  comma.split <- strsplit(DF.temp$record, ";")

  split.df <- data.frame(
      attributes = rep(DF.temp$attributes, lapply(comma.split, length)),
      record = unlist(comma.split),
      articleID = rep(DF.temp$articleID, lapply(comma.split, length)))

  #Trim whitespace on both sides
  split.df$record <- gsub("\\*", "", split.df$record)
  split.df$record <- stringr::str_trim(split.df$record, side = "both")
  split.df$record <- tolower(split.df$record)




  #Filter out all processed records from the fixed list
  DF.no.subject <- filter(full.df, attributes != "keyWord")
  DF.subject.fixed <- split.df


  #Strip author biographies

  #Bind the reduced DF with the fixed df
  DF <- rbind(DF.no.subject, DF.subject.fixed)
  DF <- arrange(DF, articleID)
    #_______________________________________________________________________________
    #                       7. Minor Cleaning
    #-------------------------------------------------------------------------------
    #
    # In this section, meaningful variable names are assigned to variables that have
    # been cleaned and are appropriate for analysis.  All other variables are
    # excluded to prevent inappropriate analyses.
    #_______________________________________________________________________________

    # Exclude UR record from the data file

    attributeKeep <- c("Article", "Author", "Publicationtitle",
        "Publicationyear", "Abstract", "keyWord", "Location", "Pages")

    attributeKeepIndex <- DF$attributes %in% attributeKeep
    DF <- DF[attributeKeepIndex,]

    DF$attributes <- tolower(DF$attributes)

    DF$attributes <- ifelse(DF$attributes == "publicationtitle", "journal", DF$attributes)
    DF$attributes <- ifelse(DF$attributes == "publicationyear", "pubYear", DF$attributes)

    # Strip white-space
    DF$record <- stringr::str_trim(DF$record, side="both")


    rownames(DF) <- NULL
    DF <- select(DF, articleID, attributes, record)

    #_______________________________________________________________________________
    #                        8. OUTPUT
    #-------------------------------------------------------------------------------
    #
    # This final section places a datafile in the global environment, which is
    # called bwr.df.  If csv is specified as TRUE in the ebscoBWR function call,
    # a csv file is written to the user's current working directory.  A few messages
    # are written to the user's screen, providing a warning message and a few
    # quality checks to ensure the number of articles matches the number of sources.
    #_______________________________________________________________________________

    proQuestBWR.df <<- DF
    if(csv == TRUE){write.csv(bwr.df, "bwrDF.csv")}

    cat(
        "****************************************************
              Wrangling is complete
****************************************************")

    if(csv == TRUE){cat(
        "\nThe `bwrDF.csv` file can be found in your working directory.\n")}

}

