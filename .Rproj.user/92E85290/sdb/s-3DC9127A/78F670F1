{
    "contents" : "#' Converts bibliographic text files extracted from ProQuest into analyzable data frame\n#' @param path - path for the folder containing text files to be wrangled\n#' @param rmDuplicates logical vector indicating whether the function should identify and remove duplicate article records\n#' @param csv - logical vector indicating whether the final data frame generated by the function should be saved to the working directory as a .csv file\n#' @examples proQuestBWR.f(csv=TRUE, path=\"C:/Users/JohnDoe/Desktop/ProQuestTextFiles\")\n#' @note proQuestBWR.f will wrangle all text files present in the path folder.  \n#' @export\n\n\nproQuestBWR.f <- function(path, rmDuplicates=TRUE, csv = FALSE){\n\n  #_______________________________________________________________________________\n  #                       0. Install Missing Packages\n  #-------------------------------------------------------------------------------\n  #\n  #All files to be wrangled should be saved in a single folder and have a *.txt\n  #extension.  The files must be processed from EbscoHost in the generic\n  #bibliographic format -- no other file structure will work.\n  #\n  #_______________________________________________________________________________\n\n  pkgs <- c(\"dplyr\", \"stringi\", \"stringr\")\n  pkgs_miss <- pkgs[which(!pkgs %in% installed.packages()[, 1])]\n  if (length(pkgs_miss) > 0) {\n    message(\"\\n ...Installing missing packages!\\n\")\n    install.packages(pkgs_miss)\n  }\n\n  if (length(pkgs_miss) == 0) {\n    message(\"\\n ...Packages were already installed!\\n\")\n  }\n\n    #___________________________________________________________________________\n    #                           1. READ ProQuest txt files\n    #---------------------------------------------------------------------------\n    #\n    # Check last line of txt file.  Clean up might be necessary\n    #___________________________________________________________________________\n\n    library(dplyr)\n    temp <- list.files(path, pattern = \".txt\", full.names=TRUE)\n    record <- unlist(lapply(temp, readLines, warn=FALSE))\n\n    # extract attributes as a separate variable\n    attributes <- stringr::str_extract(record, \"(.*?):\")\n    full.df <- data.frame(cbind(attributes, record))\n  \n    full.df$articleID <- cumsum(grepl(\"________\", full.df$record))\n\n    full.df <- tbl_df(full.df) #Convert to dplyr table for easier reading\n    full.df <- filter(full.df, record != \"\") #Eliminate empy rows\n    full.df <- filter(full.df, record = !(is.na(attributes))) #Eliminate missing\n    full.df$attributes <- gsub(\" \", \"\", full.df$attributes)\n    full.df$attributes <- gsub(\":\", \"\", full.df$attributes)\n\n    full.df$record <- gsub(\"^[^:]+:\", \"\", full.df$record)\n    \n    \n    full.df$record <- ifelse(full.df$attributes==\"Publicationdetails\", \n                                 gsub(\"\\\\s\\\\(.*\", \"\", full.df$record), full.df$record)\n    \n    full.df$attributes <- ifelse(full.df$attributes == \"Title\", \n                                 \"Article\", full.df$attributes)\n    full.df$attributes <- ifelse(full.df$attributes== \"Documentauthor\", \n                                 \"Author\", full.df$attributes)\n    full.df$attributes <- ifelse(full.df$attributes == \"Publicationdetails\", \n                                 \"Publicationtitle\", full.df$attributes)\n    full.df$attributes <- ifelse(full.df$attributes == \"Subject\",\n                                \"keyWord\", full.df$attributes)\n  \n    attributeKeep <- c(\"Article\", \"Author\", \"Publicationtitle\",\n                     \"Publicationyear\", \"Abstract\", \"keyWord\", \"Location\", \"Pages\")\n  \n    attributeKeepIndex <- full.df$attributes %in% attributeKeep\n    full.df <- full.df[attributeKeepIndex,]\n  \n  \n  #_______________________________________________________________________________\n  #                    2.  REMOVE DUPLICATE RECORDS\n  #-------------------------------------------------------------------------------\n  # In this section, the code is doing a global match for duplicate article records \n  # based on the title. Duplicates occur because multiple databases have overlapping indexing.\n  #_______________________________________________________________________________\n  \n  if(rmDuplicates==TRUE)\n    \n    #Select out all titles\n  {DF.temp <- filter(full.df, attributes == \"Article\")\n   \n   #Journal titles show discrepancies in capitalization rules.  Force all to\n   #lower to address this problem.  Further testing should consider stripping\n   #white space.\n   DF.temp$record <- tolower(DF.temp$record)\n   \n   #Find duplicated records - duplicates are marked as true\n   DF.temp <- DF.temp[duplicated(DF.temp$record), ]\n   \n   #Screen out duplicated records by articleID. The articleID must be used\n   #because the duplicate title contains other article attributes\n   DF.duplicated.ID <- DF.temp$articleID\n   full.df <- full.df[!(full.df$articleID %in% DF.duplicated.ID), ]\n   \n   rm(DF.temp, DF.duplicated.ID)\n  }\n    #_______________________________________________________________________________\n    #            3. AUTHOR FIELD FIX - AUTHORS IN SINGLE FIELD\n    #-------------------------------------------------------------------------------\n    #\n    # Social Work abstracts lists authors in a single cell, separated by a semi-\n    # colon, and then includes digits and email addresses in some occassions.\n    # The following text locates each author in the cell and places it into a new\n    # row to be consistent with PsychInfo and SSA.\n    #_______________________________________________________________________________\n\n\n        #Create a new temporary data frame\n        DF.temp <- filter(full.df, attributes == \"Author\")\n\n        #Identify records with semi-colons in author names\n        semi.colons <- grepl(\"(;)\", DF.temp$record)\n\n        #Select out those records with semi-colons in author names from temporary\n        #data frame\n        DF.temp <- DF.temp[semi.colons, ]\n\n        #Add a semi colon to the end of every string\n        DF.temp$record <- paste(DF.temp$record, \";\", sep=\"\")\n        semi.colon.split <- strsplit(DF.temp$record, \";\")\n\n        split.df <- data.frame(\n            attributes = rep(DF.temp$attributes, lapply(semi.colon.split, length)),\n            record = unlist(semi.colon.split),\n            articleID = rep(DF.temp$articleID, lapply(semi.colon.split, length)))\n\n        #Trim whitespace on both sides\n        split.df$record <- stringr::str_trim(split.df$record, side = \"both\")\n\n        #Eliminate author affiliation from author record\n        split.df$record <- gsub(\"1\\\\s.+\", \"\", split.df$record)\n\n        #Eliminate remaining number from author record\n        split.df$record <- gsub(\"1\", \"\", split.df$record)\n\n        # Create a vector of all articleID's that were fixed\n        fixed.ID <- unique(split.df$articleID)\n\n        #Filter out all processed records from the fixed list\n        DF.authors <- filter(full.df, attributes == \"Author\")\n        DF.authors.good <- DF.authors[!(DF.authors$articleID %in% fixed.ID),]\n        DF.authors.fixed <- split.df\n        DF.no.authors <- filter(full.df, attributes != \"Author\")\n\n        #Strip author biographies\n        DF.authors.good$record <- gsub(\"11\\\\s.+\", \"\", DF.authors.good$record)\n\n        #Bind the reduced DF with the fixed df\n        full.df <- rbind(DF.no.authors, DF.authors.good, DF.authors.fixed)\n        full.df <- arrange(full.df, articleID)\n\n  #_______________________________________________________________________________\n  #           4. KEYWORD FIELD FIX - KEYWORDS IN SINGLE FIELD\n  #-------------------------------------------------------------------------------\n  #\n  # Social Work abstracts lists authors in a single cell, separated by a semi-\n  # colon, and then includes digits and email addresses in some occassions.\n  # The following text locates each author in the cell and places it into a new\n  # row to be consistent with PsychInfo and SSA.\n  #_______________________________________________________________________________\n\n\n  #Create a new temporary data frame\n  \n  DF.temp <- filter(full.df, attributes == \"keyWord\")\n\n  #Add a comma to the end of every string\n  DF.temp$record <- paste(DF.temp$record, \";\", sep=\"\")\n  comma.split <- strsplit(DF.temp$record, \";\")\n\n  split.df <- data.frame(\n      attributes = rep(DF.temp$attributes, lapply(comma.split, length)),\n      record = unlist(comma.split),\n      articleID = rep(DF.temp$articleID, lapply(comma.split, length)))\n\n  #Trim whitespace on both sides\n  split.df$record <- gsub(\"\\\\*\", \"\", split.df$record)\n  split.df$record <- stringr::str_trim(split.df$record, side = \"both\")\n  split.df$record <- tolower(split.df$record)\n\n\n\n\n  #Filter out all processed records from the fixed list\n  DF.no.subject <- filter(full.df, attributes != \"keyWord\")\n  DF.subject.fixed <- split.df\n\n\n  #Bind the reduced DF with the fixed df\n  DF <- rbind(DF.no.subject, DF.subject.fixed)\n  DF <- arrange(DF, articleID)\n    #_______________________________________________________________________________\n    #                       5. Minor Cleaning\n    #-------------------------------------------------------------------------------\n    #\n    # In this section, meaningful variable names are assigned to variables that have\n    # been cleaned and are appropriate for analysis.  All other variables are\n    # excluded to prevent inappropriate analyses.\n    #_______________________________________________________________________________\n\n    DF$attributes <- tolower(DF$attributes)    \n    DF$attributes <- ifelse(DF$attributes == \"keyword\", \"keyWord\", DF$attributes)\n    DF$attributes <- ifelse(DF$attributes == \"publicationtitle\", \"journal\", DF$attributes)\n    DF$attributes <- ifelse(DF$attributes == \"publicationyear\", \"pubYear\", DF$attributes)\n\n    # Strip white-space\n    DF$record <- stringr::str_trim(DF$record, side=\"both\")\n\n\n    rownames(DF) <- NULL\n    DF <- select(DF, articleID, attributes, record)\n\n    #_______________________________________________________________________________\n    #                        6. OUTPUT\n    #-------------------------------------------------------------------------------\n    #\n    # This final section places a datafile in the global environment, which is\n    # called bwr.df.  If csv is specified as TRUE in the ebscoBWR function call,\n    # a csv file is written to the user's current working directory.  A few messages\n    # are written to the user's screen, providing a warning message and a few\n    # quality checks to ensure the number of articles matches the number of sources.\n    #_______________________________________________________________________________\n\n    proQuestBWR.df <<- DF\n    if(csv == TRUE){write.csv(proQuestBWR.df, file=\"proQuestBWR.csv\")}\n\n    cat(\n        \"****************************************************\n              Wrangling is complete\n****************************************************\")\n\n    if(csv == TRUE){cat(\n        \"\\nThe `proQuestBWR.csv` file can be found in your working directory:\\n\", getwd())}\n\n}\n\n",
    "created" : 1441036484810.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3731747750",
    "id" : "78F670F1",
    "lastKnownWriteTime" : 1441849527,
    "path" : "~/GitHub/BibWrangleR/R/proquestBWR.R",
    "project_path" : "R/proquestBWR.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}