{
    "contents" : "#' Converts bibliographic text files extracted from ProQuest into analyzable data frame\n#' @param csv - logical vector indicating whether the final data frame generated by the function should be saved to the working directory as a .csv file\n#' @param path - path for the folder containing text files to be wrangled\n#' @examples proQuestBWR.f(csv=TRUE, path=\"C:/Users/JohnDoe/Desktop/ProQuestTextFiles\")\n#' @note proQuestBWR.f will wrangle all text files present in the path folder.  \n#' @export\n\n\nproQuestBWR.f <- function(csv = FALSE, path){\n\n  #_______________________________________________________________________________\n  #                       0. Install Missing Packages\n  #-------------------------------------------------------------------------------\n  #\n  #All files to be wrangled should be saved in a single folder and have a *.txt\n  #extension.  The files must be processed from EbscoHost in the generic\n  #bibliographic format -- no other file structure will work.\n  #\n  #_______________________________________________________________________________\n\n  path <- \"/Users/beperron/Git/SocialWorkResearch/Data/proQuest\"\n  pkgs <- c(\"dplyr\", \"stringi\", \"stringr\")\n  pkgs_miss <- pkgs[which(!pkgs %in% installed.packages()[, 1])]\n  if (length(pkgs_miss) > 0) {\n    message(\"\\n ...Installing missing packages!\\n\")\n    install.packages(pkgs_miss)\n  }\n\n  if (length(pkgs_miss) == 0) {\n    message(\"\\n ...Packages were already installed!\\n\")\n  }\n\n    #___________________________________________________________________________\n    #                           1. READ ProQuest txt files\n    #---------------------------------------------------------------------------\n    #\n    # Check last line of txt file.  Clean up might be necessary\n    #___________________________________________________________________________\n\n    library(dplyr)\n    temp <- list.files(path, pattern = \".txt\", full.names=TRUE)\n    record <- unlist(lapply(temp, readLines))\n\n    indx <- which(grepl('\\\\_{10}', record))\n    record[indx+2] <- paste0('Article: ', record[indx+2])\n\n\n    # extract attributes as a separate variable\n    attributes <- stringr::str_extract(record, \"(.*?):\")\n    full.df <- data.frame(cbind(attributes, record))\n\n    full.df <- tbl_df(full.df) #Convert to dplyr table for easier reading\n    full.df <- filter(full.df, record != \"\") #Eliminate empy rows\n    full.df <- filter(full.df, record = !(is.na(attributes))) #Eliminate missing\n    full.df$attributes <- gsub(\" \", \"\", full.df$attributes)\n    full.df$attributes <- gsub(\":\", \"\", full.df$attributes)\n\n    full.df$articleID <- cumsum(full.df$attributes == \"Article\")\n    full.df$record <- gsub(\"^[^:]+:\", \"\", full.df$record)\n\n    #_______________________________________________________________________________\n    #            AUTHOR FIELD FIX - AUTHORS IN SINGLE FIELD\n    #-------------------------------------------------------------------------------\n    #\n    # Social Work abstracts lists authors in a single cell, separated by a semi-\n    # colon, and then includes digits and email addresses in some occassions.\n    # The following text locates each author in the cell and places it into a new\n    # row to be consistent with PsychInfo and SSA.\n    #_______________________________________________________________________________\n\n\n        #Create a new temporary data frame\n        DF.temp <- filter(full.df, attributes == \"Author\")\n\n        #Identify records with semi-colons in author names\n        semi.colons <- grepl(\"(;)\", DF.temp$record)\n\n        #Select out those records with semi-colons in author names from temporary\n        #data frame\n        DF.temp <- DF.temp[semi.colons, ]\n\n        #Add a semi colon to the end of every string\n        DF.temp$record <- paste(DF.temp$record, \";\", sep=\"\")\n        semi.colon.split <- strsplit(DF.temp$record, \";\")\n\n        split.df <- data.frame(\n            attributes = rep(DF.temp$attributes, lapply(semi.colon.split, length)),\n            record = unlist(semi.colon.split),\n            articleID = rep(DF.temp$articleID, lapply(semi.colon.split, length)))\n\n        #Trim whitespace on both sides\n        split.df$record <- stringr::str_trim(split.df$record, side = \"both\")\n\n        #Eliminate author affiliation from author record\n        split.df$record <- gsub(\"1\\\\s.+\", \"\", split.df$record)\n\n        #Eliminate remaining number from author record\n        split.df$record <- gsub(\"1\", \"\", split.df$record)\n\n        # Create a vector of all articleID's that were fixed\n        fixed.ID <- unique(split.df$articleID)\n\n        #Filter out all processed records from the fixed list\n        DF.authors <- filter(full.df, attributes == \"Author\")\n        DF.authors.good <- DF.authors[!(DF.authors$articleID %in% fixed.ID),]\n        DF.authors.fixed <- split.df\n        DF.no.authors <- filter(full.df, attributes != \"Author\")\n\n        #Strip author biographies\n        DF.authors.good$record <- gsub(\"11\\\\s.+\", \"\", DF.authors.good$record)\n\n        #Bind the reduced DF with the fixed df\n        DF <- rbind(DF.no.authors, DF.authors.good, DF.authors.fixed)\n        DF <- arrange(DF, articleID)\n\n  #_______________________________________________________________________________\n  #            KEYWORD FIELD FIX - KEYWORDS IN SINGLE FIELD\n  #-------------------------------------------------------------------------------\n  #\n  # Social Work abstracts lists authors in a single cell, separated by a semi-\n  # colon, and then includes digits and email addresses in some occassions.\n  # The following text locates each author in the cell and places it into a new\n  # row to be consistent with PsychInfo and SSA.\n  #_______________________________________________________________________________\n\n\n  #Create a new temporary data frame\n  full.df$attributes <- ifelse(full.df$attributes == \"Subject\",\n        \"keyWord\", full.df$attributes)\n\n  DF.temp <- filter(full.df, attributes == \"keyWord\")\n\n  #Add a comma to the end of every string\n  DF.temp$record <- paste(DF.temp$record, \";\", sep=\"\")\n  comma.split <- strsplit(DF.temp$record, \";\")\n\n  split.df <- data.frame(\n      attributes = rep(DF.temp$attributes, lapply(comma.split, length)),\n      record = unlist(comma.split),\n      articleID = rep(DF.temp$articleID, lapply(comma.split, length)))\n\n  #Trim whitespace on both sides\n  split.df$record <- gsub(\"\\\\*\", \"\", split.df$record)\n  split.df$record <- stringr::str_trim(split.df$record, side = \"both\")\n  split.df$record <- tolower(split.df$record)\n\n\n\n\n  #Filter out all processed records from the fixed list\n  DF.no.subject <- filter(full.df, attributes != \"keyWord\")\n  DF.subject.fixed <- split.df\n\n\n  #Strip author biographies\n\n  #Bind the reduced DF with the fixed df\n  DF <- rbind(DF.no.subject, DF.subject.fixed)\n  DF <- arrange(DF, articleID)\n    #_______________________________________________________________________________\n    #                       7. Minor Cleaning\n    #-------------------------------------------------------------------------------\n    #\n    # In this section, meaningful variable names are assigned to variables that have\n    # been cleaned and are appropriate for analysis.  All other variables are\n    # excluded to prevent inappropriate analyses.\n    #_______________________________________________________________________________\n\n    # Exclude UR record from the data file\n\n    attributeKeep <- c(\"Article\", \"Author\", \"Publicationtitle\",\n        \"Publicationyear\", \"Abstract\", \"keyWord\", \"Location\", \"Pages\")\n\n    attributeKeepIndex <- DF$attributes %in% attributeKeep\n    DF <- DF[attributeKeepIndex,]\n\n    DF$attributes <- tolower(DF$attributes)\n\n    DF$attributes <- ifelse(DF$attributes == \"publicationtitle\", \"journal\", DF$attributes)\n    DF$attributes <- ifelse(DF$attributes == \"publicationyear\", \"pubYear\", DF$attributes)\n\n    # Strip white-space\n    DF$record <- stringr::str_trim(DF$record, side=\"both\")\n\n\n    rownames(DF) <- NULL\n    DF <- select(DF, articleID, attributes, record)\n\n    #_______________________________________________________________________________\n    #                        8. OUTPUT\n    #-------------------------------------------------------------------------------\n    #\n    # This final section places a datafile in the global environment, which is\n    # called bwr.df.  If csv is specified as TRUE in the ebscoBWR function call,\n    # a csv file is written to the user's current working directory.  A few messages\n    # are written to the user's screen, providing a warning message and a few\n    # quality checks to ensure the number of articles matches the number of sources.\n    #_______________________________________________________________________________\n\n    proQuestBWR.df <<- DF\n    if(csv == TRUE){write.csv(bwr.df, \"bwrDF.csv\")}\n\n    cat(\n        \"****************************************************\n              Wrangling is complete\n****************************************************\")\n\n    if(csv == TRUE){cat(\n        \"\\nThe `bwrDF.csv` file can be found in your working directory.\\n\")}\n\n}\n\n",
    "created" : 1441036484810.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "946392332",
    "id" : "78F670F1",
    "lastKnownWriteTime" : 1441037299,
    "path" : "~/GitHub/BibWrangleR/BibWrangleR/R/proquestBWR.R",
    "project_path" : "R/proquestBWR.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}