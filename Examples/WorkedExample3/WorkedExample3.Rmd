---
title: "BibWrangleR"
output: html_document
date: "December 23, 2014"
uthor: Brian Perron
---

# Initialize workspace and functions

```{r warning=FALSE, message=FALSE}
# Step 1.  Clear workspace
rm(list=ls())

# Step 2.  Read BWR functions
source("/Users/beperron/Git/BibWrangleR/functions/piWrangleR.R")
source("/Users/beperron/Git/BibWrangleR/functions/packages.R")
```

```{r eval=FALSE}
# Step 3.  Set the path where original raw data are stored
setwd("/Users/beperron/Git/SocialWorkResearch")
```
```{r}
# Step 4. Set the working directory to store files created by BWR functions
my.path <- "/Users/beperron/Git/SocialWorkResearch"
```


# Wrangle the data

```{r message=FALSE, warning=FALSE, cache=TRUE}
piBWR.f(csv=TRUE, path=my.path)
```





A wide variety of analyses can be performed with these two data files.  

## Number of articles over time


```{r message=FALSE, warning=FALSE, comment=NA, cache=TRUE}

pi.match <-DF
library(dplyr)
library(doBy)
library(ggplot2)
library(gridExtra)
library(stringi)
library(stringr)

```


# Unique journals
```{r}





```


```{r}
n.articles.year <- filter(pi.match, attributes == "YR") %>%
    mutate(attributes = as.numeric(attributes))
   year.split <- split(n.articles.year, n.articles.year$record)
year.count <- unlist(lapply(year.split, nrow))
year.count <- year.count[order(names(year.count))]
years <- names(year.count)

df <- data.frame(years, year.count)
rownames(df) <- NULL

print.data.frame(df, rownames=FALSE)

plot.article.count <- ggplot(df, aes(as.factor(years), y= year.count, group=1)) + 
    geom_line(colour="red") +
    geom_point(colour="red") + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
    xlab("year") + 
    ylab("count") + 
    ggtitle("Number of Studies by Year")

df$years <- as.numeric(df$years)
plot.article.cumulative <- ggplot(df, aes(x = years, y = cumsum(year.count))) + 
    geom_line(colour="blue") +
    geom_point(colour="blue") + 
    theme(axis.text.x = element_text(angle=45, hjust=1)) +
    scale_x_continuous(breaks=pretty(df$years)) +
    xlab("year") +  
    ylab("count") +
    ggtitle("Cumulative Frequency")

grid.arrange(plot.article.count, plot.article.cumulative, ncol=2)
```

## Topic areas (by article keywords)

It is easy to explore some of the different fields within the PsychInfo data frame.  For example, each record has one or more subject terms (from the article keywords).  The total number, unique number, and most frequently occuring key words can be easily computed.  It is, indeed, a bit odd to see _test validity_, _psychometrics_, and _test reliability_ as most frequently occuring keywords among articles with "Qualitative Research" as a document classifier.  However, be reminded that these data were obtained only for purposes of demonstrating the `BWR` scripts, and no substantive inferences from these data should be made.     

```{r comment=NA, warning=FALSE, message=FALSE}

pi.df <-DF
library(stringr)
library(dplyr)
library(ggplot2)
df.2 <- filter(pi.df, attributes == "SU")
subject.terms <- str_split(df.2$record, pattern = ";")
subject.terms <- unlist(lapply(subject.terms, function(x) gsub(" ", "", x)))
subject.terms.total <- length(unlist(lapply(subject.terms, function(x) gsub(" ", "", x))))
subject.terms.unique <- length(unique(subject.terms))

subject.terms.l <- list(subject.terms.total = subject.terms.total,
                      subject.terms.unique = subject.terms.unique)

most.frequent <- as.data.frame(table(subject.terms))
most.frequent <- arrange(most.frequent, desc(Freq))
most.frequent.t <- head(most.frequent, 50)

print(subject.terms.l)
print(most.frequent.t)

```

## Number of authors
```{r comment=NA, message=FALSE, warning=FALSE}
n.authors.article <- pi.match %>% 
    filter(attributes == "AU") %>%
    select(id = articleID, author= record) %>%
    mutate(id = as.numeric(id))

n_authors <- n.authors.article %>% 
        group_by(id) %>%
        summarise(n = n())


ggplot(n_authors, aes(x = n)) + geom_bar()

summary(n_authors$n)

```

## Number of authors over time
```{r message=FALSE, comment=NA, warning=FALSE, fig.height=2, fig.height=4}
df.2 <- tbl_df(pi.match)
year <- df.2 %>%
        filter(attributes == "YR") %>%
        select(id = articleID, year = record)

authors <- df.2 %>%
        filter(attributes == "AU") %>%
        select(id = articleID, author = record)

n_authors <- authors %>%
        group_by(id) %>%
        summarise(n=n())

n_authors <- n_authors %>% 
        left_join(year) %>%
        group_by(year) %>%
        summarise(median.n = median(n))




plot.article.count <- ggplot(n_authors, aes(as.factor(year), y=median.n, group=1)) + 
    geom_line(colour="red") +
    geom_point(colour="red") + 
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) + 
    xlab("year") + 
    ylab("frequency") + 
    ggtitle("Median Number of Authors by Year")

print(n_authors)
plot.article.count
```

## How Many International Contributors?

We can look at affiliation and determine how many international contributors.  That is, the author affiliations `AF` in the database can be searched using a _regular expression_.  The regular expression searches for the characters `US` without any characters immediately preceding or proceding.  A quick review of the author affiliations suggests this is a satisfactory search strategy.  

```{r}
df.affiliations <- pi.match %>%
                filter(attributes == "AF")

us.aff <- ifelse(grepl("US", df.affiliations$record, perl=TRUE) == TRUE, "US", 
          ifelse(grepl("Canada", df.affiliations$record, perl=TRUE ) == TRUE, "Canada", 
          ifelse(grepl("Kong", df.affiliations$record, perl=TRUE ) == TRUE, "Hong Kong", 
          ifelse(grepl("China", df.affiliations$record, perl=TRUE) == TRUE, "China", 
          ifelse(grepl("Israel", df.affiliations$record, perl=TRUE) == TRUE, "Israel", "Other" )))))

affiliations <- data.frame(cbind(df.affiliations,us.aff))

ggplot(data=df.affiliations, aes(x = factor(us.aff))) + geom_bar(colour="blue", fill="blue")
```

# Analysis of Citation Reports (Web of Science)

This section looks at the Citation Reports from the wrangled data set.  The following code does some basic data preparation and then computes summary statitsics on the average number of citations per year.  

```{r}
wos.df <- wos.df %>% 
         mutate(AverageperYear = as.numeric(AverageperYear)) %>%
         arrange(desc(AverageperYear))

summary(wos.df$AverageperYear)
head(wos.df[,c("Title", "AverageperYear")], 15)
```